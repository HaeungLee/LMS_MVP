"""
EduGPT ÌÜµÌï©ÏùÑ ÏúÑÌïú ÌïòÏù¥Î∏åÎ¶¨Îìú AI Ï†úÍ≥µÏûê ÏãúÏä§ÌÖú
- OpenAI API ÌÇ§Í∞Ä ÏûàÏúºÎ©¥ OpenAI ÏÇ¨Ïö©
- ÏóÜÏúºÎ©¥ OpenRouter API ÌÇ§Î°ú Î¨¥Î£å/Ï†ÄÎπÑÏö© Î™®Îç∏ ÏÇ¨Ïö©
- Phase 9: EduGPT ÌÜµÌï© Ïãú ÎπÑÏö© Ìö®Ïú®Ï†Å Ïö¥ÏòÅ
"""

import os
import logging
import requests
import json
from typing import Optional, Dict, Any, Union, List
from enum import Enum
from dataclasses import dataclass

from app.core.config import settings

logger = logging.getLogger(__name__)

class EduGPTProvider(Enum):
    """EduGPTÏóêÏÑú ÏÇ¨Ïö©Ìï† AI Ï†úÍ≥µÏûê"""
    OPENAI_DIRECT = "openai_direct"      # OpenAI API ÏßÅÏ†ë ÏÇ¨Ïö©
    OPENROUTER_FALLBACK = "openrouter"   # OpenRouter Ìè¥Î∞±

@dataclass
class EduGPTConfig:
    """EduGPT AI ÏÑ§Ï†ï"""
    provider: EduGPTProvider
    model_name: str
    api_key: str
    base_url: str
    temperature: float = 0.7
    max_tokens: int = 4096

@dataclass
class AIMessage:
    """AI Î©îÏãúÏßÄ Íµ¨Ï°∞"""
    role: str
    content: str

class HybridAIProvider:
    """
    EduGPTÏö© ÌïòÏù¥Î∏åÎ¶¨Îìú AI Ï†úÍ≥µÏûê
    OpenAI -> OpenRouter ÏàúÏÑúÎ°ú Ìè¥Î∞±
    """
    
    def __init__(self):
        self.config = self._determine_provider()
        
        # ÏÜçÏÑ± Ï∂îÍ∞Ä (ÌÖåÏä§Ìä∏Ïö©)
        self.current_provider = self.config.provider.value if self.config else "none"
        self.openai_available = self.config and self.config.provider == EduGPTProvider.OPENAI_DIRECT
        self.openrouter_available = self.config and self.config.provider == EduGPTProvider.OPENROUTER_FALLBACK
        
    def _determine_provider(self) -> EduGPTConfig:
        """ÏÇ¨Ïö©Ìï† AI Ï†úÍ≥µÏûê Í≤∞Ï†ï"""
        
        # 1ÏàúÏúÑ: OpenAI API ÌÇ§ ÌôïÏù∏
        openai_key = os.getenv("OPENAI_API_KEY") or getattr(settings, 'OPENAI_API_KEY', None)
        
        if openai_key and openai_key.startswith("sk-"):
            logger.info("üîë OpenAI API key detected - using OpenAI for EduGPT")
            return EduGPTConfig(
                provider=EduGPTProvider.OPENAI_DIRECT,
                model_name="gpt-3.5-turbo",
                api_key=openai_key,
                base_url="https://api.openai.com/v1",
                temperature=0.7,
                max_tokens=4096
            )
        
        # 2ÏàúÏúÑ: OpenRouter API ÌÇ§ ÏÇ¨Ïö©
        openrouter_key = os.getenv("OPENROUTER_API_KEY") or getattr(settings, 'OPENROUTER_API_KEY', None)
        
        if openrouter_key:
            logger.info("üîÑ No OpenAI key - using OpenRouter for EduGPT (cost-effective)")
            return EduGPTConfig(
                provider=EduGPTProvider.OPENROUTER_FALLBACK,
                model_name="mistralai/mistral-7b-instruct:free",
                api_key=openrouter_key,
                base_url="https://openrouter.ai/api/v1",
                temperature=0.7,
                max_tokens=4096
            )
        
        raise ValueError("‚ùå No AI API keys found. Please set OPENAI_API_KEY or OPENROUTER_API_KEY")
    
    def chat_completion(self, messages: List[AIMessage], **kwargs) -> Dict[str, Any]:
        """Ï±ÑÌåÖ ÏôÑÏÑ± API Ìò∏Ï∂ú"""
        
        # Î©îÏãúÏßÄ ÌòïÏãù Î≥ÄÌôò
        formatted_messages = [
            {"role": msg.role, "content": msg.content} 
            for msg in messages
        ]
        
        # API ÏöîÏ≤≠ Íµ¨ÏÑ±
        headers = {
            "Authorization": f"Bearer {self.config.api_key}",
            "Content-Type": "application/json"
        }
        
        if self.config.provider == EduGPTProvider.OPENROUTER_FALLBACK:
            headers.update({
                "HTTP-Referer": "https://lms-mvp.com",
                "X-Title": "LMS MVP - EduGPT Integration"
            })
        
        payload = {
            "model": self.config.model_name,
            "messages": formatted_messages,
            "temperature": kwargs.get("temperature", self.config.temperature),
            "max_tokens": kwargs.get("max_tokens", self.config.max_tokens)
        }
        
        try:
            response = requests.post(
                f"{self.config.base_url}/chat/completions",
                headers=headers,
                json=payload,
                timeout=60
            )
            response.raise_for_status()
            return response.json()
            
        except Exception as e:
            logger.error(f"‚ùå AI API call failed: {e}")
            raise
    
    def generate_text(self, prompt: str, **kwargs) -> str:
        """ÌÖçÏä§Ìä∏ ÏÉùÏÑ± (Í∞ÑÎã®Ìïú Ïù∏ÌÑ∞ÌéòÏù¥Ïä§)"""
        
        messages = [AIMessage(role="user", content=prompt)]
        response = self.chat_completion(messages, **kwargs)
        
        return response["choices"][0]["message"]["content"]
    
    async def generate_response(self, prompt: str, temperature: float = 0.7, max_tokens: int = 1000) -> str:
        """ÎπÑÎèôÍ∏∞ ÏùëÎãµ ÏÉùÏÑ± (EduGPT ÌÜµÌï©Ïö©)"""
        return self.generate_text(prompt, temperature=temperature, max_tokens=max_tokens)
    
    def get_provider_info(self) -> Dict[str, Any]:
        """ÌòÑÏû¨ ÏÇ¨Ïö© Ï§ëÏù∏ Ï†úÍ≥µÏûê Ï†ïÎ≥¥"""
        return {
            "provider": self.config.provider.value,
            "model": self.config.model_name,
            "is_free": self.config.provider == EduGPTProvider.OPENROUTER_FALLBACK,
            "cost_optimization": True if self.config.provider == EduGPTProvider.OPENROUTER_FALLBACK else False
        }
    
    def estimate_cost(self, input_tokens: int, output_tokens: int) -> float:
        """ÌÜ†ÌÅ∞ ÏÇ¨Ïö©Îüâ Í∏∞Î∞ò ÎπÑÏö© Ï∂îÏ†ï"""
        
        if self.config.provider == EduGPTProvider.OPENROUTER_FALLBACK:
            if "free" in self.config.model_name:
                return 0.0  # Î¨¥Î£å Î™®Îç∏
            else:
                return (input_tokens + output_tokens) * 0.001 / 1000  # $0.001 per 1K tokens
        
        elif self.config.provider == EduGPTProvider.OPENAI_DIRECT:
            # OpenAI GPT-3.5-turbo ÎπÑÏö©
            input_cost = input_tokens * 0.0015 / 1000   # $0.0015 per 1K input tokens
            output_cost = output_tokens * 0.002 / 1000  # $0.002 per 1K output tokens
            return input_cost + output_cost
        
        return 0.0

# Ï†ÑÏó≠ Ïù∏Ïä§ÌÑ¥Ïä§
_hybrid_provider = None

def get_hybrid_ai_provider() -> HybridAIProvider:
    """ÌïòÏù¥Î∏åÎ¶¨Îìú AI Ï†úÍ≥µÏûê Ïã±Í∏ÄÌÜ§"""
    global _hybrid_provider
    if _hybrid_provider is None:
        _hybrid_provider = HybridAIProvider()
    return _hybrid_provider

def generate_curriculum(subject: str, level: str, weeks: int = 12) -> str:
    """Ïª§Î¶¨ÌÅòÎüº ÏÉùÏÑ± (EduGPT ÌÜµÌï©Ïö©)"""
    
    prompt = f"""
    Îã§Ïùå Ï°∞Í±¥Ïóê ÎßûÎäî {weeks}Ï£ºÏ∞® Ïª§Î¶¨ÌÅòÎüºÏùÑ ÏÉùÏÑ±Ìï¥Ï£ºÏÑ∏Ïöî:
    
    Í≥ºÎ™©: {subject}
    ÏàòÏ§Ä: {level}
    Í∏∞Í∞Ñ: {weeks}Ï£º
    
    Í∞Å Ï£ºÏ∞®Î≥ÑÎ°ú Îã§ÏùåÏùÑ Ìè¨Ìï®Ìï¥Ï£ºÏÑ∏Ïöî:
    - Ï£ºÏ∞® Ï†úÎ™©
    - ÌïôÏäµ Î™©Ìëú
    - Ï£ºÏöî ÎÇ¥Ïö©
    - Ïã§Ïäµ ÌôúÎèô
    - ÌèâÍ∞Ä Î∞©Î≤ï
    
    JSON ÌòïÏãùÏúºÎ°ú ÏùëÎãµÌï¥Ï£ºÏÑ∏Ïöî.
    """
    
    provider = get_hybrid_ai_provider()
    return provider.generate_text(prompt, temperature=0.7, max_tokens=3000)

def generate_teaching_response(context: str, student_question: str) -> str:
    """ÍµêÏàò ÏùëÎãµ ÏÉùÏÑ± (EduGPT Ìã∞Ïπ≠ ÏóêÏù¥Ï†ÑÌä∏Ïö©)"""
    
    prompt = f"""
    Îã§Ïùå Îß•ÎùΩÏóêÏÑú ÌïôÏÉùÏùò ÏßàÎ¨∏Ïóê ÎãµÎ≥ÄÌï¥Ï£ºÏÑ∏Ïöî:
    
    Îß•ÎùΩ: {context}
    ÌïôÏÉù ÏßàÎ¨∏: {student_question}
    
    ÍµêÏú°Ï†ÅÏù¥Í≥† Ïù¥Ìï¥ÌïòÍ∏∞ Ïâ¨Ïö¥ ÎãµÎ≥ÄÏùÑ Ï†úÍ≥µÌï¥Ï£ºÏÑ∏Ïöî.
    """
    
    provider = get_hybrid_ai_provider()
    return provider.generate_text(prompt, temperature=0.8, max_tokens=1500)

def log_ai_usage(operation: str, tokens_used: int = 0):
    """AI ÏÇ¨Ïö©Îüâ Î°úÍπÖ"""
    provider = get_hybrid_ai_provider()
    info = provider.get_provider_info()
    
    logger.info(f"ü§ñ EduGPT AI Usage - Operation: {operation}, "
                f"Provider: {info['provider']}, Model: {info['model']}, "
                f"Tokens: {tokens_used}, Cost-Optimized: {info['cost_optimization']}")

# Phase 9 ÌÜµÌï©ÏùÑ ÏúÑÌïú Ïú†Ìã∏Î¶¨Ìã∞ Ìï®ÏàòÎì§
def check_ai_availability() -> Dict[str, Any]:
    """AI Ï†úÍ≥µÏûê Í∞ÄÏö©ÏÑ± Ï≤¥ÌÅ¨"""
    try:
        provider = get_hybrid_ai_provider()
        info = provider.get_provider_info()
        return {
            "available": True,
            "provider": info["provider"],
            "model": info["model"],
            "is_free": info["is_free"],
            "status": "ready"
        }
    except Exception as e:
        return {
            "available": False,
            "error": str(e),
            "status": "error"
        }

def get_recommended_settings() -> Dict[str, Any]:
    """EduGPT ÌÜµÌï©ÏùÑ ÏúÑÌïú Í∂åÏû• ÏÑ§Ï†ï"""
    provider = get_hybrid_ai_provider()
    
    if provider.config.provider == EduGPTProvider.OPENAI_DIRECT:
        return {
            "curriculum_generation": {
                "model": "gpt-3.5-turbo",
                "temperature": 0.7,
                "max_tokens": 3000
            },
            "teaching_agent": {
                "model": "gpt-3.5-turbo", 
                "temperature": 0.8,
                "max_tokens": 1500
            }
        }
    else:
        return {
            "curriculum_generation": {
                "model": "mistralai/mistral-7b-instruct:free",
                "temperature": 0.6,
                "max_tokens": 2000
            },
            "teaching_agent": {
                "model": "mistralai/mistral-7b-instruct:free",
                "temperature": 0.7,
                "max_tokens": 1000
            }
        }
