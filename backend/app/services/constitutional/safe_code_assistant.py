# -*- coding: utf-8 -*-
"""
Safe Code Assistant - Constitutional AI ê¸°ë°˜ ì½”ë“œ ë¦¬ë·° ì‹œìŠ¤í…œ

3ë‹¨ê³„ ê²€ì¦:
1. Safety (ë³´ì•ˆ ì·¨ì•½ì  ê²€ì‚¬)
2. Ethics (ìœ¤ë¦¬ì  ë¬¸ì œ ê²€ì‚¬)
3. Education (êµìœ¡ì  í”¼ë“œë°± ìƒì„±)
"""
import re
from typing import List, Dict, Optional
from pydantic import BaseModel
from datetime import datetime
import logging

from app.core.anthropic_client import anthropic_client

logger = logging.getLogger(__name__)


# ============================================================
# Pydantic ëª¨ë¸
# ============================================================

class SecurityVulnerability(BaseModel):
    """ë³´ì•ˆ ì·¨ì•½ì """
    type: str  # "SQL_INJECTION", "XSS", "COMMAND_INJECTION" ë“±
    severity: str  # "critical", "high", "medium", "low"
    line_number: Optional[int] = None
    description: str
    safe_alternative: str


class EthicalIssue(BaseModel):
    """ìœ¤ë¦¬ì  ë¬¸ì œ"""
    type: str  # "MALWARE", "PRIVACY_VIOLATION", "COPYRIGHT_INFRINGEMENT" ë“±
    description: str
    reason: str


class CodeReview(BaseModel):
    """ì½”ë“œ ë¦¬ë·° ê²°ê³¼"""
    safe_to_run: bool
    vulnerabilities: List[SecurityVulnerability]
    ethical_issues: List[EthicalIssue]
    educational_feedback: Optional[str] = None
    reviewed_at: datetime = datetime.utcnow()


# ============================================================
# Safe Code Assistant í´ë˜ìŠ¤
# ============================================================

class SafeCodeAssistant:
    """
    Constitutional AI ê¸°ë°˜ ì½”ë“œ ì–´ì‹œìŠ¤í„´íŠ¸
    
    ê¸°ëŠ¥:
    - ë³´ì•ˆ ì·¨ì•½ì  ìë™ íƒì§€
    - ìœ¤ë¦¬ì  ë¬¸ì œ ê²€ì‚¬
    - êµìœ¡ì  í”¼ë“œë°± ìƒì„± (Claude)
    """
    
    def __init__(self):
        self.anthropic = anthropic_client
        
        # ë³´ì•ˆ íŒ¨í„´ (ì •ê·œí‘œí˜„ì‹)
        self.security_patterns = {
            "SQL_INJECTION": [
                (r'\.execute\(["\'].*%s.*["\']\s*%', "String formatting in SQL query"),
                (r'\.execute\(["\'].*\+.*["\']\)', "String concatenation in SQL query"),
                (r'\.execute\(f["\'].*\{.*\}.*["\']\)', "f-string in SQL query"),
                (r'cursor\.execute\(["\'][^"\']*["\']\.format\(', "str.format() in SQL query"),
            ],
            "COMMAND_INJECTION": [
                (r'os\.system\(["\'][^"\']*\{.*\}', "User input in os.system()"),
                (r'subprocess\.(call|run|Popen)\(.*shell\s*=\s*True', "shell=True with user input"),
                (r'eval\(', "eval() with potential user input"),
                (r'exec\(', "exec() with potential user input"),
            ],
            "UNSAFE_DESERIALIZATION": [
                (r'pickle\.loads\(', "pickle.loads() - Remote Code Execution risk"),
                (r'yaml\.load\([^,]*\)', "yaml.load() without SafeLoader"),
            ],
            "HARDCODED_SECRETS": [
                (r'(password|passwd|pwd)\s*=\s*["\'][^"\']{3,}["\']', "Hardcoded password"),
                (r'(api_key|apikey|api_secret)\s*=\s*["\'][^"\']{10,}["\']', "Hardcoded API key"),
                (r'(token|secret|private_key)\s*=\s*["\'][^"\']{10,}["\']', "Hardcoded secret"),
            ],
            "WEAK_CRYPTO": [
                (r'hashlib\.(md5|sha1)\(', "Weak hashing algorithm (MD5/SHA1)"),
                (r'random\.(randint|choice|random)\(', "Non-cryptographic random (use secrets module)"),
            ],
            "PATH_TRAVERSAL": [
                (r'open\(.*\+.*user', "User input in file path"),
                (r'open\(f["\'].*\{.*\}', "f-string with user input in file path"),
            ]
        }
        
        # ìœ¤ë¦¬ì  íŒ¨í„´ (í‚¤ì›Œë“œ ê¸°ë°˜)
        self.ethical_keywords = {
            "MALWARE": [
                "malware", "virus", "trojan", "ransomware", "keylogger",
                "backdoor", "rootkit", "ìŠ¤íŒŒì´ì›¨ì–´", "ì•…ì„±ì½”ë“œ"
            ],
            "HACKING_TOOLS": [
                "brute.?force", "crack.*password", "sql.*injection.*tool",
                "exploit.*kit", "port.*scanner", "vulnerability.*scanner",
                "ë¹„ë°€ë²ˆí˜¸.*í¬ë˜í‚¹", "í•´í‚¹.*ë„êµ¬"
            ],
            "DDOS": [
                "ddos", "denial.*of.*service", "flood.*attack", "ì„œë¹„ìŠ¤.*ê±°ë¶€"
            ],
            "PRIVACY_VIOLATION": [
                "keylogger", "screen.*capture.*stealth", "hidden.*camera",
                "spy.*software", "ê°œì¸ì •ë³´.*ë¬´ë‹¨.*ìˆ˜ì§‘"
            ],
            "SPAM": [
                "mass.*email.*sender", "spam.*bot", "auto.*follow.*bot",
                "ìŠ¤íŒ¸.*ë°œì†¡", "ìë™.*ë©”ì‹œì§€.*ë´‡"
            ]
        }
    
    async def review_code(
        self,
        code: str,
        language: str,
        user_level: str = "beginner"
    ) -> CodeReview:
        """
        ì½”ë“œ ë¦¬ë·° (3ë‹¨ê³„ ê²€ì¦)
        
        Args:
            code: ê²€í† í•  ì½”ë“œ
            language: í”„ë¡œê·¸ë˜ë° ì–¸ì–´
            user_level: í•™ìŠµì ë ˆë²¨
        
        Returns:
            CodeReview: ì „ì²´ ë¦¬ë·° ê²°ê³¼
        """
        logger.info(f"Reviewing {language} code (user_level: {user_level})")
        
        # Step 1: ë³´ì•ˆ ì·¨ì•½ì  ê²€ì‚¬
        vulnerabilities = await self._check_safety(code, language)
        
        # Step 2: ìœ¤ë¦¬ì  ë¬¸ì œ ê²€ì‚¬
        ethical_issues = await self._check_ethics(code)
        
        # Step 3: êµìœ¡ì  í”¼ë“œë°± ìƒì„± (Claude)
        educational_feedback = None
        if vulnerabilities or ethical_issues:
            # ë¬¸ì œê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ í”¼ë“œë°± ìƒì„±
            educational_feedback = await self._generate_educational_feedback(
                code=code,
                language=language,
                vulnerabilities=vulnerabilities,
                ethical_issues=ethical_issues,
                user_level=user_level
            )
        
        # ì‹¤í–‰ ì•ˆì „ì„± íŒë‹¨
        safe_to_run = (
            len(vulnerabilities) == 0 and 
            len(ethical_issues) == 0
        )
        
        return CodeReview(
            safe_to_run=safe_to_run,
            vulnerabilities=vulnerabilities,
            ethical_issues=ethical_issues,
            educational_feedback=educational_feedback
        )
    
    async def _check_safety(
        self,
        code: str,
        language: str
    ) -> List[SecurityVulnerability]:
        """
        ë³´ì•ˆ ì·¨ì•½ì  ê²€ì‚¬
        
        ì •ê·œí‘œí˜„ì‹ ê¸°ë°˜ íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ë¹ ë¥´ê²Œ íƒì§€
        """
        vulnerabilities = []
        code_lower = code.lower()
        
        # Python ì½”ë“œë§Œ ê²€ì‚¬ (ë‹¤ë¥¸ ì–¸ì–´ëŠ” ì¶”í›„ í™•ì¥)
        if language.lower() != "python":
            return vulnerabilities
        
        for vuln_type, patterns in self.security_patterns.items():
            for pattern, description in patterns:
                matches = re.finditer(pattern, code, re.IGNORECASE)
                
                for match in matches:
                    # ë¼ì¸ ë²ˆí˜¸ ê³„ì‚°
                    line_number = code[:match.start()].count('\n') + 1
                    
                    # ì‹¬ê°ë„ íŒë‹¨
                    severity = self._determine_severity(vuln_type)
                    
                    # ì•ˆì „í•œ ëŒ€ì•ˆ ì œì‹œ
                    safe_alternative = self._get_safe_alternative(vuln_type)
                    
                    vulnerabilities.append(SecurityVulnerability(
                        type=vuln_type,
                        severity=severity,
                        line_number=line_number,
                        description=description,
                        safe_alternative=safe_alternative
                    ))
        
        return vulnerabilities
    
    async def _check_ethics(self, code: str) -> List[EthicalIssue]:
        """
        ìœ¤ë¦¬ì  ë¬¸ì œ ê²€ì‚¬
        
        í‚¤ì›Œë“œ ê¸°ë°˜ íƒì§€ + ì»¨í…ìŠ¤íŠ¸ ë¶„ì„
        """
        ethical_issues = []
        code_lower = code.lower()
        
        for issue_type, keywords in self.ethical_keywords.items():
            for keyword in keywords:
                # ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ í‚¤ì›Œë“œ ê²€ìƒ‰
                if re.search(keyword, code_lower):
                    # ë°œê²¬ëœ ê²½ìš°
                    description = self._get_ethical_issue_description(issue_type)
                    reason = self._get_ethical_reason(issue_type)
                    
                    ethical_issues.append(EthicalIssue(
                        type=issue_type,
                        description=description,
                        reason=reason
                    ))
                    break  # ì¤‘ë³µ ë°©ì§€
        
        return ethical_issues
    
    async def _generate_educational_feedback(
        self,
        code: str,
        language: str,
        vulnerabilities: List[SecurityVulnerability],
        ethical_issues: List[EthicalIssue],
        user_level: str
    ) -> str:
        """
        êµìœ¡ì  í”¼ë“œë°± ìƒì„± (Claude ì‚¬ìš©)
        
        Constitutional AI ì›ì¹™ì„ ì ìš©í•œ ì¹œì ˆí•˜ê³  êµìœ¡ì ì¸ í”¼ë“œë°±
        """
        try:
            feedback = await self.anthropic.generate_with_constitutional_ai(
                user_code=code,
                language=language,
                user_level=user_level,
                vulnerabilities=[v.dict() for v in vulnerabilities],
                ethical_issues=[e.dict() for e in ethical_issues]
            )
            return feedback
        except Exception as e:
            logger.error(f"Failed to generate educational feedback: {e}")
            # Fallback: ê¸°ë³¸ í”¼ë“œë°±
            return self._generate_fallback_feedback(vulnerabilities, ethical_issues)
    
    def _determine_severity(self, vuln_type: str) -> str:
        """ì·¨ì•½ì  ì‹¬ê°ë„ íŒë‹¨"""
        critical = ["SQL_INJECTION", "COMMAND_INJECTION", "UNSAFE_DESERIALIZATION"]
        high = ["HARDCODED_SECRETS", "PATH_TRAVERSAL"]
        medium = ["WEAK_CRYPTO"]
        
        if vuln_type in critical:
            return "critical"
        elif vuln_type in high:
            return "high"
        elif vuln_type in medium:
            return "medium"
        else:
            return "low"
    
    def _get_safe_alternative(self, vuln_type: str) -> str:
        """ì•ˆì „í•œ ëŒ€ì•ˆ ì½”ë“œ ì˜ˆì‹œ"""
        alternatives = {
            "SQL_INJECTION": "cursor.execute('SELECT * FROM users WHERE id = ?', (user_id,))",
            "COMMAND_INJECTION": "subprocess.run(['ping', host], shell=False, check=True)",
            "UNSAFE_DESERIALIZATION": "json.loads(data) ë˜ëŠ” ast.literal_eval() ì‚¬ìš©",
            "HARDCODED_SECRETS": "os.getenv('API_KEY') ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©",
            "WEAK_CRYPTO": "hashlib.sha256() ë˜ëŠ” bcrypt ì‚¬ìš©",
            "PATH_TRAVERSAL": "Path('/uploads').resolve() / filename (pathlib ì‚¬ìš©)"
        }
        return alternatives.get(vuln_type, "ì•ˆì „í•œ ëŒ€ì•ˆì„ ì°¾ì•„ë³´ì„¸ìš”.")
    
    def _get_ethical_issue_description(self, issue_type: str) -> str:
        """ìœ¤ë¦¬ì  ë¬¸ì œ ì„¤ëª…"""
        descriptions = {
            "MALWARE": "ì•…ì„±ì½”ë“œ ë˜ëŠ” ë°”ì´ëŸ¬ìŠ¤ ê´€ë ¨ ì½”ë“œ",
            "HACKING_TOOLS": "í•´í‚¹ ë„êµ¬ ë˜ëŠ” ë¬´ë‹¨ ì ‘ê·¼ ì‹œë„",
            "DDOS": "ì„œë¹„ìŠ¤ ê±°ë¶€ ê³µê²© (DDoS)",
            "PRIVACY_VIOLATION": "ê°œì¸ì •ë³´ ë³´í˜¸ ìœ„ë°˜",
            "SPAM": "ìŠ¤íŒ¸ ë°œì†¡ ë„êµ¬"
        }
        return descriptions.get(issue_type, "ìœ¤ë¦¬ì  ë¬¸ì œ ë°œê²¬")
    
    def _get_ethical_reason(self, issue_type: str) -> str:
        """ìœ¤ë¦¬ì  ë¬¸ì œ ì´ìœ """
        reasons = {
            "MALWARE": "ì•…ì„±ì½”ë“œ ì œì‘ ë° ë°°í¬ëŠ” ë¶ˆë²•ì´ë©° íƒ€ì¸ì—ê²Œ í”¼í•´ë¥¼ ì¤ë‹ˆë‹¤.",
            "HACKING_TOOLS": "ë¬´ë‹¨ ì ‘ê·¼ ë„êµ¬ëŠ” ë¶ˆë²•ì´ë©° ê°œì¸ì •ë³´ë¥¼ ì¹¨í•´í•©ë‹ˆë‹¤.",
            "DDOS": "ì„œë¹„ìŠ¤ ê±°ë¶€ ê³µê²©ì€ ë¶ˆë²•ì´ë©° ë‹¤ë¥¸ ì‚¬ìš©ìì—ê²Œ í”¼í•´ë¥¼ ì¤ë‹ˆë‹¤.",
            "PRIVACY_VIOLATION": "ë™ì˜ ì—†ëŠ” ê°œì¸ì •ë³´ ìˆ˜ì§‘ì€ ë¶ˆë²•ì…ë‹ˆë‹¤.",
            "SPAM": "ìŠ¤íŒ¸ ë°œì†¡ì€ ë¶ˆë²•ì´ë©° íƒ€ì¸ì—ê²Œ í”¼í•´ë¥¼ ì¤ë‹ˆë‹¤."
        }
        return reasons.get(issue_type, "ë¹„ìœ¤ë¦¬ì  ì½”ë“œì…ë‹ˆë‹¤.")
    
    def _generate_fallback_feedback(
        self,
        vulnerabilities: List[SecurityVulnerability],
        ethical_issues: List[EthicalIssue]
    ) -> str:
        """Claude API ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í”¼ë“œë°±"""
        feedback_parts = []
        
        if vulnerabilities:
            feedback_parts.append("ğŸ”´ **ë³´ì•ˆ ì·¨ì•½ì  ë°œê²¬:**\n")
            for v in vulnerabilities:
                feedback_parts.append(
                    f"- [{v.severity.upper()}] {v.type}: {v.description}\n"
                    f"  ğŸ’¡ ì•ˆì „í•œ ëŒ€ì•ˆ: {v.safe_alternative}\n"
                )
        
        if ethical_issues:
            feedback_parts.append("\nğŸš« **ìœ¤ë¦¬ì  ë¬¸ì œ ë°œê²¬:**\n")
            for e in ethical_issues:
                feedback_parts.append(
                    f"- {e.type}: {e.description}\n"
                    f"  ì´ìœ : {e.reason}\n"
                )
        
        return "\n".join(feedback_parts)


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
safe_code_assistant = SafeCodeAssistant()

