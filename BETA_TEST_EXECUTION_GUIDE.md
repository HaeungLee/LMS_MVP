# 🧪 LMS MVP 베타 테스트 실행 가이드

## 📋 테스트 개요
Phase 1-4 완료 후 베타 테스트를 위한 종합 테스트 시나리오입니다.

## 🎯 테스트 대상 기능
### ✅ Phase 1: 기본 인증 및 문제 풀이 시스템
### ✅ Phase 2: AI 피드백 시스템  
### ✅ Phase 3: 확장성 인프라 (Redis, Celery, 레이트리밋)
### ✅ Phase 4: AI 고도화 (멘토링, 분석, 적응형 학습)

---

## 🚀 1. 시스템 시작 및 확인

### 1.1 서비스 상태 확인
```bash
# 데이터베이스 확인
docker ps | findstr lms_mvp_db_container

# 백엔드 API 확인 
curl http://localhost:8000/docs

# 프론트엔드 확인
# 브라우저에서 http://localhost:5175 접속
```

### 1.2 초기 데이터 시드 확인
```bash
cd backend
python -m scripts.seed_taxonomy      # 카테고리/주제 데이터
python -m scripts.seed_teacher       # 교사 계정
python -m scripts.seed_admin         # 관리자 계정
python -m scripts.seed_questions     # 샘플 문제
```

---

## 👤 2. 사용자 인증 테스트

### 2.1 회원가입 테스트
1. **기본 회원가입**
   - 이메일: `beta_user1@test.com`
   - 비밀번호: `testpass123`
   - 이름: `베타테스터1`

2. **중복 이메일 처리** ✅
   - 같은 이메일로 재가입 시도
   - 적절한 오류 메시지 확인

3. **비밀번호 규칙 확인** ✅
   - 8자 미만: 거부되어야 함
   - 특수문자 없음: 거부되어야 함

### 2.2 로그인 테스트
1. **정상 로그인**
   - 생성한 계정으로 로그인
   - 대시보드 리다이렉트 확인

2. **기존 테스트 계정**
   - 교사: `test@test.com` / `test`
   - 관리자: `admin@admin.com` / `admin`

3. **Remember Me 기능** ✅
   - 체크박스 선택 시 30일 유지
   - 브라우저 재시작 후에도 로그인 상태 유지

---

## 📚 3. 문제 풀이 기본 기능 테스트

### 3.1 문제 목록 및 필터링
1. **카테고리 필터** ✅
   - 프로그래밍 기초, 알고리즘, 웹 개발 등
   - 선택한 카테고리의 문제만 표시

2. **난이도 필터** ✅
   - 초급, 중급, 고급 필터링
   - 난이도별 문제 수 확인

3. **페이징** ✅
   - 문제 목록 페이지네이션
   - 페이지당 10개 문제 표시

### 3.2 문제 풀이 플로우
1. **객관식 문제**
   - 4개 선택지 중 1개 선택
   - 제출 시 즉시 채점
   - 정답/오답 표시

2. **주관식 문제**
   - 텍스트 입력 또는 코드 작성
   - AI 피드백 요청 가능
   - 저장 및 임시저장 기능

3. **제출 내역 확인**
   - 제출한 답안 목록
   - 점수 및 피드백 확인

---

## 🤖 4. AI 피드백 시스템 테스트

### 4.1 기본 AI 피드백 (Phase 2)
1. **주관식 답안 피드백**
   - 코드 작성 후 "AI 피드백 요청" 클릭
   - OpenRouter API 응답 시간 측정 (< 10초)
   - 피드백 품질 확인 (구체적이고 도움되는 내용)

2. **코드 품질 분석**
   - Python, JavaScript 코드 제출
   - 문법, 로직, 성능 피드백 확인
   - 개선 제안사항 검토

### 4.2 고급 AI 기능 테스트 (Phase 4)
1. **AI 멘토링 시스템** 🆕
   ```
   테스트 경로: /ai-features
   ```
   - 다양한 멘토 유형 선택 (격려형, 분석형, 실무형 등)
   - 대화형 질문-답변
   - 학습 팁 및 동기부여 메시지

2. **심층 학습 분석** 🆕
   - 사용자 학습 패턴 분석
   - 강점/약점 식별
   - 학습자 유형 분류 (빠른 학습자, 심층 사고자 등)

3. **적응형 난이도 조절** 🆕
   - 최근 성과 기반 난이도 추천
   - 실시간 메트릭 (정확도, 응답시간 등)
   - 다음 추천 문제 난이도

4. **개인화 학습 경로** 🆕
   - 목표 기반 커리큘럼 생성
   - 학습 스케줄 최적화
   - 마일스톤 및 진도 추적

5. **AI 코드 리뷰** 🆕
   - 다중 언어 지원 (Python, JavaScript, Java)
   - 5단계 품질 평가
   - 보안, 성능, 가독성 종합 분석

---

## ⚡ 5. 확장성 인프라 테스트 (Phase 3)

### 5.1 레이트리밋 테스트
1. **기본 API 호출 제한**
   - 빠른 연속 요청 (초당 10회 이상)
   - 제한 메시지 확인: "Too Many Requests"

2. **AI 기능 특별 제한**
   - AI 피드백 요청 5회/10분 제한
   - 제한 초과 시 적절한 안내 메시지

3. **사용자 등급별 차등 제한** ✅
   - FREE 사용자: 기본 제한
   - PREMIUM/ADMIN: 확장된 제한

### 5.2 캐싱 시스템 테스트
1. **Redis 캐싱** (Redis 서버 실행 시)
   - 동일 AI 요청 재전송 시 빠른 응답 (캐시 히트)
   - 캐시 만료 시간 확인 (1시간)

2. **메모리 폴백** (Redis 미연결 시)
   - Redis 없이도 정상 동작
   - 메모리 기반 임시 캐싱

### 5.3 성능 모니터링
1. **모니터링 API 확인**
   ```bash
   curl http://localhost:8000/api/v1/monitoring/health
   curl http://localhost:8000/api/v1/monitoring/system/health
   curl http://localhost:8000/api/v1/monitoring/metrics/system
   ```

2. **시스템 상태 추적**
   - CPU, 메모리 사용률
   - API 응답 시간
   - 동시 접속자 수

---
## 🔄 6. 동시 사용자 부하 테스트

### 6.1 다중 브라우저 테스트
1. **5-10명 동시 로그인**
   - Chrome, Firefox, Edge 등 다른 브라우저
   - 각각 다른 계정으로 로그인
   - 동시에 문제 풀이 및 AI 기능 사용

2. **동시 AI 요청**
   - 여러 사용자가 동시에 AI 피드백 요청
   - 응답 시간 및 성공률 확인
   - 서버 에러 발생 여부

### 6.2 성능 임계점 테스트
1. **응답 시간 측정**
   - 1명: < 1초
   - 5명: < 2초
   - 10명: < 3초
   - 15명 이상: 확장성 상태 확인

2. **에러율 모니터링**
   - 정상: < 1% 에러율
   - 주의: 1-5% 에러율  
   - 위험: > 5% 에러율

---

## 🎨 7. 프론트엔드 UI/UX 테스트

### 7.1 반응형 디자인
1. **데스크톱** (1920x1080)
   - 모든 요소 정상 표시
   - 레이아웃 깨짐 없음

2. **태블릿** (768x1024)
   - 네비게이션 메뉴 적응
   - 버튼 크기 적절

3. **모바일** (375x667)
   - 터치 인터페이스 최적화
   - 스크롤 및 입력 편의성

### 7.2 사용자 경험
1. **네비게이션**
   - 직관적인 메뉴 구조
   - 빵부스러기 네비게이션
   - 로그인/로그아웃 상태 표시

2. **피드백 표시**
   - 로딩 상태 표시
   - 성공/실패 메시지
   - 진행률 표시

3. **접근성**
   - 키보드 네비게이션
   - 스크린 리더 호환성
   - 색상 대비 적절성

---

## 🔍 8. 관리자 기능 테스트

### 8.1 문제 관리 (`admin@admin.com`)
1. **문제 출제**
   - 새 문제 등록
   - 카테고리/난이도 설정
   - 정답 및 해설 입력

2. **문제 편집**
   - 기존 문제 수정
   - 삭제 기능
   - 비활성화 설정

### 8.2 교사 대시보드 (`test@test.com`)
1. **통계 확인**
   - 주제별 문제 수
   - 학생별 정답률
   - 최근 제출 내역

2. **피드백 관리**
   - AI 피드백 품질 확인
   - 수동 피드백 추가

---

## 📊 9. 데이터 및 보안 테스트

### 9.1 데이터 무결성
1. **사용자 데이터**
   - 회원정보 저장/수정
   - 제출 내역 보존
   - 학습 진도 추적

2. **AI 응답 데이터**
   - 피드백 내용 저장
   - 응답 시간 기록
   - 사용량 통계

### 9.2 보안 테스트
1. **인증 보안**
   - JWT 토큰 유효성
   - 세션 만료 처리
   - CSRF 토큰 검증

2. **API 보안**
   - 권한 없는 접근 차단
   - SQL 인젝션 방지
   - XSS 공격 방지

---

## 🚨 10. 오류 시나리오 테스트

### 10.1 API 실패 처리
1. **AI API 장애**
   - OpenRouter API 키 잘못 설정
   - 네트워크 연결 실패
   - 적절한 폴백 메시지 확인

2. **데이터베이스 연결 실패**
   - 데이터베이스 컨테이너 중지
   - 연결 풀 고갈
   - 에러 처리 및 복구

### 10.2 사용자 입력 오류
1. **잘못된 입력**
   - 빈 값 제출
   - 너무 긴 텍스트
   - 특수문자 처리

2. **세션 만료**
   - 장시간 비활성
   - 토큰 만료 후 요청
   - 자동 로그인 페이지 리다이렉트

---

## 📈 11. 성과 지표 측정

### 11.1 기술적 지표
- [ ] **가용성**: 99%+ (테스트 기간 중 다운타임 최소화)
- [ ] **응답시간**: 평균 < 2초
- [ ] **AI 성공률**: 95%+ (AI 요청 중 성공적 응답)
- [ ] **에러율**: < 1% (전체 요청 중 에러 비율)

### 11.2 사용자 경험 지표
- [ ] **회원가입 완료율**: 90%+
- [ ] **첫 문제 풀이 완료율**: 80%+
- [ ] **AI 기능 사용률**: 70%+ (가입자 중 AI 기능 사용)
- [ ] **세션 지속 시간**: 평균 30분+

### 11.3 AI 기능 지표
- [ ] **멘토링 대화 품질**: 만족도 4.0/5.0+
- [ ] **코드 리뷰 정확성**: 기본 70점+ 보장
- [ ] **학습 분석 유용성**: 개인화 추천 활용도 60%+
- [ ] **적응형 난이도 정확성**: 성과 개선율 20%+

---

## 🎯 12. 테스트 완료 체크리스트

### ✅ 필수 통과 항목
- [ ] 기본 회원가입/로그인 정상 동작
- [ ] 문제 풀이 및 제출 기능 완전 작동
- [ ] AI 피드백 기본 기능 안정적 제공
- [ ] 5명 이상 동시 사용자 지원
- [ ] 관리자/교사 기능 정상 작동
- [ ] 모바일 반응형 디자인 적용
- [ ] 보안 기본 요구사항 충족

### 🏆 우수 달성 항목
- [ ] 모든 AI 고도화 기능 완전 작동
- [ ] 20명 동시 사용자 안정적 지원
- [ ] 실시간 모니터링 시스템 활용
- [ ] 레이트리밋 및 캐싱 최적화
- [ ] 사용자 피드백 5점 만점 중 4점 이상
- [ ] 장애 복구 시나리오 성공적 처리

---

## 🛠️ 13. 문제 발생 시 대응 방안

### 13.1 즉시 해결 가능한 문제
- **프론트엔드 에러**: 브라우저 콘솔 확인, 캐시 클리어
- **API 응답 실패**: 백엔드 로그 확인, 서비스 재시작
- **로그인 문제**: 토큰 초기화, 쿠키 삭제

### 13.2 기술 지원 요청 사항
- **AI API 한도 초과**: OpenRouter 사용량 확인
- **데이터베이스 성능 저하**: 쿼리 최적화 필요
- **동시 접속 한계**: 서버 리소스 증설 고려

### 13.3 문제 보고 양식
```
문제 유형: [로그인/AI기능/성능/UI 등]
발생 시간: [정확한 시간]
재현 단계: [1. 2. 3. ...]
예상 결과: [어떻게 동작해야 하는지]
실제 결과: [실제로 어떻게 동작했는지]
브라우저/환경: [Chrome 124, Windows 11 등]
스크린샷: [첨부 가능하면]
```

---
## 🎉 14. 베타 테스트 성공 기준

### 🎯 최소 성공 기준 (통과)
- 핵심 기능 95% 정상 동작
- 심각한 보안 이슈 0건
- 5명 동시 사용자 안정적 지원
- 사용자 만족도 3.5/5.0 이상

### 🏆 우수 성공 기준 (추천)
- 모든 기능 100% 정상 동작
- AI 기능 활용도 80% 이상
- 20명 동시 사용자 완전 지원
- 사용자 만족도 4.5/5.0 이상
- 베타 테스터 재사용 의향 90% 이상

---

**🚀 베타 테스트를 통해 실제 사용자 관점에서 LMS MVP의 완성도를 검증하고, 정식 출시를 위한 최종 개선점을 도출합시다!**

---

**테스트 진행 순서**: 1→2→3→4→5→6→7→8→9→10→11→12 순서로 진행하되, 문제 발생 시 13번 참조하여 해결 후 계속 진행합니다.
